{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ejercicios Pandas DataFrames 02\n",
    "Carga el dataset de vuelos \"flights14.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/ricardoahumada/DataScienceBasics/raw/refs/heads/main/data/flights14.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        year  month  day  dep_delay  arr_delay carrier origin dest  air_time  \\\n",
      "1       2014      1    1         14         13      AA    JFK  LAX       359   \n",
      "2       2014      1    1         -3         13      AA    JFK  LAX       363   \n",
      "3       2014      1    1          2          9      AA    JFK  LAX       351   \n",
      "4       2014      1    1         -8        -26      AA    LGA  PBI       157   \n",
      "5       2014      1    1          2          1      AA    JFK  LAX       350   \n",
      "...      ...    ...  ...        ...        ...     ...    ...  ...       ...   \n",
      "253312  2014     10   31          1        -30      UA    LGA  IAH       201   \n",
      "253313  2014     10   31         -5        -14      UA    EWR  IAH       189   \n",
      "253314  2014     10   31         -8         16      MQ    LGA  RDU        83   \n",
      "253315  2014     10   31         -4         15      MQ    LGA  DTW        75   \n",
      "253316  2014     10   31         -5          1      MQ    LGA  SDF       110   \n",
      "\n",
      "        distance  hour  \n",
      "1           2475     9  \n",
      "2           2475    11  \n",
      "3           2475    19  \n",
      "4           1035     7  \n",
      "5           2475    13  \n",
      "...          ...   ...  \n",
      "253312      1416    14  \n",
      "253313      1400     8  \n",
      "253314       431    11  \n",
      "253315       502    11  \n",
      "253316       659     8  \n",
      "\n",
      "[253316 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Escribe un programa Pandas para dividir los datos basados en origen y destino. Muestra cada grupo y el número de elementos por grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 253316 entries, 1 to 253316\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   year       253316 non-null  int64 \n",
      " 1   month      253316 non-null  int64 \n",
      " 2   day        253316 non-null  int64 \n",
      " 3   dep_delay  253316 non-null  int64 \n",
      " 4   arr_delay  253316 non-null  int64 \n",
      " 5   carrier    253316 non-null  object\n",
      " 6   origin     253316 non-null  object\n",
      " 7   dest       253316 non-null  object\n",
      " 8   air_time   253316 non-null  int64 \n",
      " 9   distance   253316 non-null  int64 \n",
      " 10  hour       253316 non-null  int64 \n",
      "dtypes: int64(8), object(3)\n",
      "memory usage: 23.2+ MB\n",
      "Help on method groupby in module pandas.core.frame:\n",
      "\n",
      "groupby(by=None, axis: 'Axis' = 0, level: 'Level | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, squeeze: 'bool | lib.NoDefault' = <no_default>, observed: 'bool' = False, dropna: 'bool' = True) -> 'DataFrameGroupBy' method of pandas.core.frame.DataFrame instance\n",
      "    Group DataFrame using a mapper or by a Series of columns.\n",
      "    \n",
      "    A groupby operation involves some combination of splitting the\n",
      "    object, applying a function, and combining the results. This can be\n",
      "    used to group large amounts of data and compute operations on these\n",
      "    groups.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    by : mapping, function, label, or list of labels\n",
      "        Used to determine the groups for the groupby.\n",
      "        If ``by`` is a function, it's called on each value of the object's\n",
      "        index. If a dict or Series is passed, the Series or dict VALUES\n",
      "        will be used to determine the groups (the Series' values are first\n",
      "        aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      "        values are used as-is to determine the groups. A label or list of\n",
      "        labels may be passed to group by the columns in ``self``. Notice\n",
      "        that a tuple is interpreted as a (single) key.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Split along rows (0) or columns (1).\n",
      "    level : int, level name, or sequence of such, default None\n",
      "        If the axis is a MultiIndex (hierarchical), group by a particular\n",
      "        level or levels.\n",
      "    as_index : bool, default True\n",
      "        For aggregated output, return object with group labels as the\n",
      "        index. Only relevant for DataFrame input. as_index=False is\n",
      "        effectively \"SQL-style\" grouped output.\n",
      "    sort : bool, default True\n",
      "        Sort group keys. Get better performance by turning this off.\n",
      "        Note this does not influence the order of observations within each\n",
      "        group. Groupby preserves the order of rows within each group.\n",
      "    group_keys : bool, default True\n",
      "        When calling apply, add group keys to index to identify pieces.\n",
      "    squeeze : bool, default False\n",
      "        Reduce the dimensionality of the return type if possible,\n",
      "        otherwise return a consistent type.\n",
      "    \n",
      "        .. deprecated:: 1.1.0\n",
      "    \n",
      "    observed : bool, default False\n",
      "        This only applies if any of the groupers are Categoricals.\n",
      "        If True: only show observed values for categorical groupers.\n",
      "        If False: show all values for categorical groupers.\n",
      "    dropna : bool, default True\n",
      "        If True, and if group keys contain NA values, NA values together\n",
      "        with row/column will be dropped.\n",
      "        If False, NA values will also be treated as the key in groups\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrameGroupBy\n",
      "        Returns a groupby object that contains information about the groups.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    resample : Convenience method for frequency conversion and resampling\n",
      "        of time series.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    See the `user guide\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`__ for more.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      "    ...                               'Parrot', 'Parrot'],\n",
      "    ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      "    >>> df\n",
      "       Animal  Max Speed\n",
      "    0  Falcon      380.0\n",
      "    1  Falcon      370.0\n",
      "    2  Parrot       24.0\n",
      "    3  Parrot       26.0\n",
      "    >>> df.groupby(['Animal']).mean()\n",
      "            Max Speed\n",
      "    Animal\n",
      "    Falcon      375.0\n",
      "    Parrot       25.0\n",
      "    \n",
      "    **Hierarchical Indexes**\n",
      "    \n",
      "    We can groupby different levels of a hierarchical index\n",
      "    using the `level` parameter:\n",
      "    \n",
      "    >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      "    ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      "    >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      "    >>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
      "    ...                   index=index)\n",
      "    >>> df\n",
      "                    Max Speed\n",
      "    Animal Type\n",
      "    Falcon Captive      390.0\n",
      "           Wild         350.0\n",
      "    Parrot Captive       30.0\n",
      "           Wild          20.0\n",
      "    >>> df.groupby(level=0).mean()\n",
      "            Max Speed\n",
      "    Animal\n",
      "    Falcon      370.0\n",
      "    Parrot       25.0\n",
      "    >>> df.groupby(level=\"Type\").mean()\n",
      "             Max Speed\n",
      "    Type\n",
      "    Captive      210.0\n",
      "    Wild         185.0\n",
      "    \n",
      "    We can also choose to include NA in group keys or not by setting\n",
      "    `dropna` parameter, the default setting is `True`:\n",
      "    \n",
      "    >>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
      "    >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      "    \n",
      "    >>> df.groupby(by=[\"b\"]).sum()\n",
      "        a   c\n",
      "    b\n",
      "    1.0 2   3\n",
      "    2.0 2   5\n",
      "    \n",
      "    >>> df.groupby(by=[\"b\"], dropna=False).sum()\n",
      "        a   c\n",
      "    b\n",
      "    1.0 2   3\n",
      "    2.0 2   5\n",
      "    NaN 1   4\n",
      "    \n",
      "    >>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
      "    >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      "    \n",
      "    >>> df.groupby(by=\"a\").sum()\n",
      "        b     c\n",
      "    a\n",
      "    a   13.0   13.0\n",
      "    b   12.3  123.0\n",
      "    \n",
      "    >>> df.groupby(by=\"a\", dropna=False).sum()\n",
      "        b     c\n",
      "    a\n",
      "    a   13.0   13.0\n",
      "    b   12.3  123.0\n",
      "    NaN 12.3   33.0\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m help(df\u001b[38;5;241m.\u001b[39mgroupby)\n\u001b[1;32m      5\u001b[0m gdf \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdest\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mgroups\u001b[38;5;241m.\u001b[39mkeys\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g, vals \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(g, \u001b[38;5;28mlen\u001b[39m(vals))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "help(df.groupby)\n",
    "\n",
    "gdf = df.groupby(['origin','dest']).groups.keys\n",
    "\n",
    "for g, vals in gdf.items():\n",
    "    print(g, len(vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 253316 entries, 1 to 253316\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Non-Null Count   Dtype         \n",
      "---  ------     --------------   -----         \n",
      " 0   year       253316 non-null  int64         \n",
      " 1   month      253316 non-null  int64         \n",
      " 2   day        253316 non-null  int64         \n",
      " 3   dep_delay  253316 non-null  int64         \n",
      " 4   arr_delay  253316 non-null  int64         \n",
      " 5   carrier    253316 non-null  object        \n",
      " 6   origin     253316 non-null  object        \n",
      " 7   dest       253316 non-null  object        \n",
      " 8   air_time   253316 non-null  int64         \n",
      " 9   distance   253316 non-null  int64         \n",
      " 10  hour       253316 non-null  int64         \n",
      " 11  date       253316 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(8), object(3)\n",
      "memory usage: 25.1+ MB\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['total_delay'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m----> 4\u001b[0m gdf \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcarrier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_delay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m gdf\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/groupby/generic.py:979\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m    978\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m--> 979\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/apply.py:161\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/apply.py:427\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m     selected_obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_selected_obj\n\u001b[1;32m    425\u001b[0m     selection \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_selection\n\u001b[0;32m--> 427\u001b[0m arg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(selection, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/apply.py:546\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[0;34m(self, how, obj, func)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    545\u001b[0m         cols_sorted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(safe_sort(\u001b[38;5;28mlist\u001b[39m(cols)))\n\u001b[0;32m--> 546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcols_sorted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m do not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    548\u001b[0m is_aggregator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m))\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column(s) ['total_delay'] do not exist\""
     ]
    }
   ],
   "source": [
    "df['date'] =pd.to_datetime(df[['year','month','day']])\n",
    "df.info()\n",
    "\n",
    "gdf = df.groupby(['date','carrier']).agg({\"total_delay\":sum})\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5 Escribe un programa Pandas para cargar los datos de productos y ventas del archivo FoodMarket.xlsx y méclalos en un solo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/FoodMarket.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_prods \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/FoodMarket.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/io/excel/_base.py:364\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    363\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m     )\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/io/excel/_base.py:1191\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1191\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1195\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1196\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1197\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1198\u001b[0m         )\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/io/excel/_base.py:1070\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1068\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1070\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1073\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1074\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/io/common.py:711\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    703\u001b[0m             handle,\n\u001b[1;32m    704\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    707\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m         )\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/FoodMarket.xlsx'"
     ]
    }
   ],
   "source": [
    "df_prods = pd.read_excel('data/FoodMarket.xlsx', sheet_name='Product')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
